import os
import sys
import json
import logging
import zipfile
import shutil
import io
from pathlib import Path
from datetime import datetime, date
from typing import Dict, Set, List, Tuple
import math
import tkinter as tk
from tkinter import ttk, filedialog, messagebox
import customtkinter as ctk
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use("TkAgg")
import matplotlib.pyplot as plt
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg, NavigationToolbar2Tk
from matplotlib.backends.backend_pdf import PdfPages
from matplotlib.patches import Rectangle

try:
    import mplcursors
    HAS_MPLCURSORS = True
except ImportError:
    HAS_MPLCURSORS = False

from openpyxl import Workbook
from openpyxl.styles import Font, Alignment
from openpyxl.utils import get_column_letter
from openpyxl.worksheet.table import Table, TableStyleInfo

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

DEFAULT_PATHS = {
    "xrp_EXCEL_PATH": "data/xrp_Config.xlsx",
    "MASTER_ZIP_PATH": "data/Master_Config.zip",
    "MASTER_TXT_FOLDER": "",
    "EXCEPTION_PATH": "data/Exception_Table.xlsx",
    "OUTPUT_PATH": "output/missing_items.xlsx",
    "CONFIG_PATH": "config/ui_config.json",
    "PARAMETER_PATH": "data/parameters.xlsx",
    "MASTER_CSV_OUTPUT": "temp_master_csv",
    "PDF_EXPORT_PATH": "output/dashboard_report.pdf",
    "LOGO_PATH": "images/company_logo.png",
    "HISTORY_PATH": "history_runs",
    "CASE_HISTORY_PATH": "case_history_runs",
    "BOLLINGER_JSON_PATH": "data/bollinger_data.json",
    "CASE_BOLLINGER_JSON_PATH": "data/case_bollinger_data.json"
}

def default_config() -> Dict:
    return {
        "paths": DEFAULT_PATHS.copy(),
        "xrp_grid": {"filters": {}, "future_end_toggle": False},
        "master_grid": {"filters": {}, "future_end_toggle": False},
        "dashboard": {"selected_dims": [], "selected_attrs": [], "top_n": 10},
        "trim_key_toggle": False,
        "include_case_in_report": False
    }

def load_config(path: Path) -> Dict:
    if path.is_file():
        try:
            with open(path, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.warning(f"Could not load config => {e}")
    return default_config()

def save_config(cfg: Dict, path: Path):
    path.parent.mkdir(parents=True, exist_ok=True)
    try:
        for main_key in ["xrp_grid", "master_grid"]:
            if main_key in cfg and "filters" in cfg[main_key]:
                newf = {}
                for col, svals in cfg[main_key]["filters"].items():
                    newf[col] = list(svals)
                cfg[main_key]["filters"] = newf
        with open(path, "w", encoding="utf-8") as f:
            json.dump(cfg, f, indent=2)
        logging.info(f"Saved config => {path}")
    except Exception as e:
        logging.error(f"Error saving config => {e}")

class TextHandler(logging.Handler):
    def __init__(self, widget: ctk.CTkTextbox):
        super().__init__()
        self.widget = widget
    def emit(self, record):
        msg = self.format(record) + "\n"
        self.widget.after(0, self._append, msg)
    def _append(self, msg):
        if not self.widget or not self.widget.winfo_exists():
            return
        try:
            self.widget.configure(state="normal")
            self.widget.insert("end", msg)
            self.widget.see("end")
            self.widget.configure(state="disabled")
        except:
            pass

def read_param_file(path: Path) -> Dict[str, object]:
    param = {
        "dim_xrp_keep": set(),
        "dim_xrp_map": {},
        "dim_master_map": {},
        "attr_xrp_map": {},
        "attr_master_map": {}
    }
    if not path.is_file():
        logging.warning(f"Param => {path} not found.")
        return param
    try:
        dim_df = pd.read_excel(path, sheet_name="Dimension Parameters")
        dim_df.columns = dim_df.columns.astype(str).str.strip()
        def s(x) -> str:
            return str(x).strip() if pd.notna(x) else ""
        for _, row in dim_df.iterrows():
            fn  = s(row.get("FileName", ""))
            vsc = s(row.get("V S C", ""))
            dim = s(row.get("Dimension", ""))
            ev  = s(row.get("XRP Values", ""))
            if ev.lower() == "x" and vsc and dim:
                param["dim_xrp_keep"].add(vsc)
            if vsc and dim:
                param["dim_xrp_map"][vsc] = dim
            if fn and dim and ev.lower() == "x":
                param["dim_master_map"][fn] = dim
        attr_df = pd.read_excel(path, sheet_name="Attribute Parameters")
        attr_df.columns = attr_df.columns.astype(str).str.strip()
        for _, row in attr_df.iterrows():
            e_orig = s(row.get("XRP Original Attributes", ""))
            m_orig = s(row.get("Master Original Attributes", ""))
            final_ = s(row.get("Attribute", ""))
            onoff  = s(row.get("On/Off", ""))
            if onoff.lower() == "x" and final_:
                if e_orig:
                    param["attr_xrp_map"][e_orig] = final_
                if m_orig:
                    param["attr_master_map"][m_orig] = final_
        return param
    except Exception as e:
        logging.error(f"read_param_file => {e}")
        return param

def read_xrp_excel(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"XRP => not found => {path}")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path, skiprows=3)
        df.columns = df.columns.str.strip().astype(str)
        return df
    except Exception as e:
        logging.error(f"read_xrp_excel => {e}")
        return pd.DataFrame()

def try_read_csv_bytes(raw: bytes) -> pd.DataFrame:
    encs = ["utf-8-sig", "utf-16-le", "utf-16-be", "cp1252", "latin-1", "ascii"]
    for e in encs:
        try:
            buf = io.BytesIO(raw)
            df = pd.read_csv(buf, encoding=e, on_bad_lines="skip", engine="python")
            df.dropna(how="all", axis=0, inplace=True)
            df.dropna(how="all", axis=1, inplace=True)
            df.columns = df.columns.astype(str).str.strip()
            if "Name" not in df.columns and len(df.columns) > 0:
                fc = df.columns[0]
                df.rename(columns={fc: "Name"}, inplace=True)
            return df
        except:
            pass
    logging.error("All encoding attempts failed => empty DF")
    return pd.DataFrame()

def unify_master_txt_in_folder(folder: Path) -> pd.DataFrame:
    if not folder.is_dir():
        logging.warning(f"Master folder => not exist => {folder}")
        return pd.DataFrame()
    frames = []
    for f in folder.glob("*.txt"):
        try:
            raw = f.read_bytes()
            df_ = try_read_csv_bytes(raw)
            if not df_.empty:
                df_["RawFileName"] = f.name
                frames.append(df_)
        except Exception as e:
            logging.error(f"unify_master_txt_in_folder => {f} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

def convert_master_txt_to_csv(zip_path: Path, out_dir: Path) -> List[Path]:
    if not zip_path.is_file():
        logging.warning(f"Master ZIP => not found => {zip_path}")
        return []
    if out_dir.exists():
        shutil.rmtree(out_dir, ignore_errors=True)
    out_dir.mkdir(parents=True, exist_ok=True)
    csvs = []
    with zipfile.ZipFile(zip_path, "r") as z:
        txt_files = [f for f in z.namelist() if f.lower().endswith(".txt")]
        for txtf in txt_files:
            bn = os.path.basename(txtf)
            if not bn:
                continue
            try:
                with z.open(txtf) as fo:
                    raw = fo.read()
                df = try_read_csv_bytes(raw)
                if df.empty:
                    continue
                df["RawFileName"] = bn
                out_csv = out_dir / (bn.replace(".txt", ".csv"))
                df.to_csv(out_csv, index=False, encoding="utf-8")
                csvs.append(out_csv)
            except Exception as e:
                logging.error(f"Reading {txtf} => {e}")
    return csvs

def unify_master_csvs(csvs: List[Path]) -> pd.DataFrame:
    frames = []
    for cp in csvs:
        if cp.is_file():
            try:
                df = pd.read_csv(cp, encoding="utf-8", on_bad_lines="skip")
                df.columns = df.columns.str.strip().astype(str)
                frames.append(df)
            except Exception as e:
                logging.error(f"unify_master_csvs => {cp} => {e}")
    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

def standardize_value(val, attr):
    if val is None or (isinstance(val, float) and math.isnan(val)):
        return ""
    try:
        if isinstance(val, (int, float)):
            if val == int(val):
                return str(int(val))
            else:
                return str(float(val))
        val_str = str(val).strip()
        tmp = val_str.replace('.', '', 1).replace('-', '', 1)
        if tmp.isdigit():
            num_val = float(val_str)
            if num_val == int(num_val):
                return str(int(num_val))
            else:
                return str(num_val)
    except:
        pass
    val_str = str(val).strip()
    if attr in ["Start Date", "End Date"] and "T" in val_str:
        return val_str.split("T")[0]
    return val_str

def are_values_equivalent(val1, val2):
    if val1 == val2:
        return True
    try:
        tmp1 = val1.replace('.', '', 1).replace('-', '', 1)
        tmp2 = val2.replace('.', '', 1).replace('-', '', 1)
        if tmp1.isdigit() and tmp2.isdigit():
            f1 = float(val1)
            f2 = float(val2)
            return f1 == f2
    except:
        pass
    return val1.strip() == val2.strip()

def meltdown_xrp_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if "V_S_C" not in df.columns:
        logging.warning("XRP meltdown => 'V_S_C' missing => returning empty.")
        return pd.DataFrame()
    keep = param["dim_xrp_keep"]
    dmap = param["dim_xrp_map"]
    amap = param["attr_xrp_map"]
    df2 = df[df["V_S_C"].isin(keep)].copy()
    if df2.empty:
        return pd.DataFrame()
    skip_cols = {"V_S_C"}
    id_vars = []
    if "Value" in df2.columns:
        id_vars.append("Value")
        skip_cols.add("Value")
    df2["DimRaw"] = df2["V_S_C"]
    skip_cols.add("DimRaw")
    id_vars.insert(0, "DimRaw")
    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols, var_name="OrigAttr", value_name="ValX")
    def rename_dim(v):
        return dmap.get(v, v)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Value" in id_vars:
        melted.rename(columns={"Value": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)
    melted["Value"] = melted.apply(lambda x: standardize_value(x["ValX"], x["Attribute"]), axis=1)
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def meltdown_master_for_preview(df: pd.DataFrame, param: Dict[str, object]) -> pd.DataFrame:
    if df.empty or "RawFileName" not in df.columns:
        return pd.DataFrame()
    keep_map = param["dim_master_map"]
    amap = param["attr_master_map"]
    df2 = df[df["RawFileName"].isin(keep_map.keys())].copy()
    if df2.empty:
        return pd.DataFrame()
    df2["DimRaw"] = df2["RawFileName"]
    skip_cols = {"RawFileName", "DimRaw"}
    id_vars = ["DimRaw"]
    if "Name" in df2.columns:
        id_vars.append("Name")
        skip_cols.add("Name")
    meltdown_cols = [c for c in df2.columns if c not in skip_cols]
    melted = df2.melt(id_vars=id_vars, value_vars=meltdown_cols, var_name="OrigAttr", value_name="ValX")
    def rename_dim(x):
        return keep_map.get(x, x)
    melted["Dimension"] = melted["DimRaw"].apply(rename_dim)
    if "Name" in id_vars:
        melted.rename(columns={"Name": "Name"}, inplace=True)
    else:
        melted["Name"] = ""
    melted = melted[melted["OrigAttr"].isin(amap.keys())].copy()
    melted["Attribute"] = melted["OrigAttr"].map(amap)
    melted["Value"] = melted.apply(lambda x: standardize_value(x["ValX"], x["Attribute"]), axis=1)
    return melted[["Dimension", "Name", "Attribute", "Value"]]

def pivot_for_preview(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty or not {"Dimension", "Name", "Attribute"}.issubset(df.columns):
        return pd.DataFrame()
    df2 = df.drop_duplicates(subset=["Dimension", "Name", "Attribute"])
    try:
        return df2.pivot(index=["Dimension", "Name"], columns="Attribute", values="Value").reset_index()
    except:
        return pd.DataFrame()

def meltdown_to_long(df_wide: pd.DataFrame) -> pd.DataFrame:
    if df_wide.empty or {"Dimension", "Name"}.difference(df_wide.columns):
        return pd.DataFrame()
    meltdown_cols = [c for c in df_wide.columns if c not in ("Dimension", "Name")]
    melted = df_wide.melt(id_vars=["Dimension", "Name"], value_vars=meltdown_cols, var_name="Attribute", value_name="Value")
    melted["Value"] = melted["Value"].fillna("")
    return melted

def read_exception_table(path: Path) -> pd.DataFrame:
    if not path.is_file():
        logging.warning(f"Exception => {path} not found")
        return pd.DataFrame()
    try:
        df = pd.read_excel(path)
        df.columns = df.columns.astype(str).str.strip()
        return df
    except Exception as e:
        logging.error(f"Exception => {e}")
        return pd.DataFrame()

def merge_exceptions(df: pd.DataFrame, df_exc: pd.DataFrame) -> pd.DataFrame:
    if df.empty or df_exc.empty or "Key" not in df.columns:
        return df
    needed_cols = ["Key", "Comments_1", "Comments_2", "Hide Exception"]
    exc_use = [c for c in needed_cols if c in df_exc.columns]
    if not exc_use:
        return df
    if "Hide Exception" in exc_use:
        df_exc["Hide Exception"] = df_exc["Hide Exception"].fillna("").str.lower()
    else:
        df_exc["Hide Exception"] = ""
    merged = pd.merge(df, df_exc[exc_use], on="Key", how="left", suffixes=("", "_exc"))
    hide_series = merged.get("Hide Exception", "").fillna("").str.lower()
    merged = merged[hide_series != "yes"].copy()
    if "Comments_1_exc" in merged.columns:
        merged["Comments_1"] = np.where(merged["Comments_1_exc"].fillna("").str.strip() != "", merged["Comments_1_exc"], merged["Comments_1"])
        merged.drop(columns=["Comments_1_exc"], inplace=True)
    if "Comments_2_exc" in merged.columns:
        merged["Comments_2"] = np.where(merged["Comments_2_exc"].fillna("").str.strip() != "", merged["Comments_2_exc"], merged["Comments_2"])
        merged.drop(columns=["Comments_2_exc"], inplace=True)
    if "Hide Exception" in merged.columns:
        merged.drop(columns=["Hide Exception"], inplace=True)
    return merged

def diagnose_type_mismatches(xrp_df: pd.DataFrame, master_df: pd.DataFrame):
    logging.info("Checking for potential data type mismatches...")
    common_dims = set(xrp_df["Dimension"].unique()) & set(master_df["Dimension"].unique())
    for dim in common_dims:
        xrp_subset = xrp_df[xrp_df["Dimension"] == dim]
        master_subset = master_df[master_df["Dimension"] == dim]
        common_attrs = set(xrp_subset["Attribute"].unique()) & set(master_subset["Attribute"].unique())
        for attr in common_attrs:
            xrp_values = xrp_subset[xrp_subset["Attribute"] == attr]["Value"]
            master_values = master_subset[master_subset["Attribute"] == attr]["Value"]
            xrp_types = set(type(v) for v in xrp_values if v != "")
            master_types = set(type(v) for v in master_values if v != "")
            if len(xrp_types) > 1 or len(master_types) > 1 or xrp_types != master_types:
                logging.warning(f"Data type inconsistency - Dimension: {dim}, Attribute: {attr}")
                logging.warning(f"  XRP types: {xrp_types}")
                logging.warning(f"  Master types: {master_types}")
                xrp_examples = xrp_values.head(3).tolist()
                master_examples = master_values.head(3).tolist()
                logging.warning(f"  XRP examples: {xrp_examples}")
                logging.warning(f"  Master examples: {master_examples}")

def compare_name_first(xrp_long: pd.DataFrame, mast_long: pd.DataFrame, trim_key=False) -> Tuple[pd.DataFrame, pd.DataFrame]:
    mismatch_rows = []
    case_rows = []
    def build_dict(df_):
        out = {}
        for (dim, nm), grp in df_.groupby(["Dimension", "Name"]):
            rec = {}
            for _, row in grp.iterrows():
                rec[row["Attribute"]] = row["Value"]
            out[(dim, nm)] = rec
        return out
    e_dict = build_dict(xrp_long)
    m_dict = build_dict(mast_long)
    all_dn = set(e_dict.keys()) | set(m_dict.keys())
    for dn in all_dn:
        dim, nm = dn
        e_map = e_dict.get(dn, {})
        m_map = m_dict.get(dn, {})
        name_issue = False
        if dn not in e_dict and dn in m_dict:
            m_name = m_map.get("Name", "")
            row = {
                "Dimension": dim, "Name": nm, "Attribute": "Name",
                "Master": m_name, "XRP": "",
                "Comments_1": "", "Comments_2": "", "Status": "Missing in XRP"
            }
            raw_key = f"{dim}|{nm}|Name|{m_name}|".upper()
            if trim_key:
                raw_key = raw_key.replace(" ", "")
            row["Key"] = raw_key
            mismatch_rows.append(row)
            name_issue = True
        elif dn in e_dict and dn not in m_dict:
            e_name = e_map.get("Name", "")
            row = {
                "Dimension": dim, "Name": nm, "Attribute": "Name",
                "Master": "", "XRP": e_name,
                "Comments_1": "", "Comments_2": "", "Status": "Missing in Master"
            }
            raw_key = f"{dim}|{nm}|Name||{e_name}".upper()
            if trim_key:
                raw_key = raw_key.replace(" ", "")
            row["Key"] = raw_key
            mismatch_rows.append(row)
            name_issue = True
        else:
            if "Name" in e_map and "Name" in m_map:
                ev = e_map["Name"]
                mv = m_map["Name"]
                ev_str = standardize_value(ev, "Name")
                mv_str = standardize_value(mv, "Name")
                if are_values_equivalent(ev_str, mv_str):
                    pass
                else:
                    if ev_str and mv_str and ev_str.lower() == mv_str.lower():
                        row = {
                            "Dimension": dim, "Name": nm, "Attribute": "Name",
                            "Master": mv, "XRP": ev,
                            "Comments_1": "", "Comments_2": "",
                            "Status": "CASE"
                        }
                        raw_key = f"{dim}|{nm}|Name|{mv}|{ev}".upper()
                        if trim_key:
                            raw_key = raw_key.replace(" ", "")
                        row["Key"] = raw_key
                        case_rows.append(row)
                    else:
                        row = {
                            "Dimension": dim, "Name": nm, "Attribute": "Name",
                            "Master": mv, "XRP": ev,
                            "Comments_1": "", "Comments_2": "",
                            "Status": "Difference in both"
                        }
                        raw_key = f"{dim}|{nm}|Name|{mv}|{ev}".upper()
                        if trim_key:
                            raw_key = raw_key.replace(" ", "")
                        row["Key"] = raw_key
                        mismatch_rows.append(row)
                name_issue = True
            elif "Name" not in e_map and "Name" in m_map:
                m_name = m_map["Name"]
                row = {
                    "Dimension": dim, "Name": nm, "Attribute": "Name",
                    "Master": m_name, "XRP": "",
                    "Comments_1": "", "Comments_2": "",
                    "Status": "Missing in XRP"
                }
                raw_key = f"{dim}|{nm}|Name|{m_name}|".upper()
                if trim_key:
                    raw_key = raw_key.replace(" ", "")
                row["Key"] = raw_key
                mismatch_rows.append(row)
                name_issue = True
            elif "Name" in e_map and "Name" not in m_map:
                e_name = e_map["Name"]
                row = {
                    "Dimension": dim, "Name": nm, "Attribute": "Name",
                    "Master": "", "XRP": e_name,
                    "Comments_1": "", "Comments_2": "",
                    "Status": "Missing in Master"
                }
                raw_key = f"{dim}|{nm}|Name||{e_name}".upper()
                if trim_key:
                    raw_key = raw_key.replace(" ", "")
                row["Key"] = raw_key
                mismatch_rows.append(row)
                name_issue = True
        if name_issue and (dn not in e_dict or dn not in m_dict):
            continue
        if dn in e_dict and dn in m_dict:
            all_atts = set(e_map.keys()) | set(m_map.keys())
            all_atts.discard("Name")
            for at in all_atts:
                ev_val = e_map.get(at, "")
                mv_val = m_map.get(at, "")
                ev_str = standardize_value(ev_val, at)
                mv_str = standardize_value(mv_val, at)
                if are_values_equivalent(ev_str, mv_str):
                    continue
                else:
                    if ev_str and not mv_str:
                        st = "Missing in Master"
                        ms = ""
                        es = ev_val
                    elif mv_str and not ev_str:
                        st = "Missing in XRP"
                        ms = mv_val
                        es = ""
                    else:
                        st = "Difference in both"
                        ms = mv_val
                        es = ev_val
                    row = {
                        "Dimension": dim, "Name": nm, "Attribute": at,
                        "Master": ms, "XRP": es,
                        "Comments_1": "", "Comments_2": "",
                        "Status": st
                    }
                    raw_key = f"{dim}|{nm}|{at}|{ms}|{es}".upper()
                    if trim_key:
                        raw_key = raw_key.replace(" ", "")
                    row["Key"] = raw_key
                    mismatch_rows.append(row)
    c_ = ["Key", "Dimension", "Name", "Attribute", "Master", "XRP", "Comments_1", "Comments_2", "Status"]
    mismatch_df = pd.DataFrame(mismatch_rows, columns=c_) if mismatch_rows else pd.DataFrame(columns=c_)
    case_df = pd.DataFrame(case_rows, columns=c_) if case_rows else pd.DataFrame(columns=c_)
    return mismatch_df, case_df

def write_missing_items_excel(mismatch_df: pd.DataFrame, case_df: pd.DataFrame, out_path: Path):
    if mismatch_df.empty and case_df.empty:
        logging.info("No mismatches => skip writing xlsx.")
        return
    out_path.parent.mkdir(parents=True, exist_ok=True)
    c_ = ["Key", "Dimension", "Name", "Attribute", "Master", "XRP", "Comments_1", "Comments_2", "Status", "Date"]
    for df_ in [mismatch_df, case_df]:
        for col in c_:
            if col not in df_.columns:
                df_[col] = ""
    wb = Workbook()
    ws_m = wb.active
    ws_m.title = "Mismatch"
    ws_m.append(c_)
    for rowv in mismatch_df[c_].itertuples(index=False):
        ws_m.append(rowv)
    ws_c = wb.create_sheet("Case_Differences")
    ws_c.append(c_)
    for rowv in case_df[c_].itertuples(index=False):
        ws_c.append(rowv)
    style_simple_sheet(ws_m, "MissingItemsMismatch")
    style_simple_sheet(ws_c, "MissingItemsCaseDifferences")
    wb.save(out_path)
    logging.info(f"Wrote => {out_path}")
    stamp = datetime.now().strftime("%Y-%m-%d")
    stamped = out_path.parent / f"{out_path.stem}_{stamp}{out_path.suffix}"
    wb.save(stamped)
    logging.info(f"Wrote => {stamped}")

def style_simple_sheet(ws, table_name: str):
    max_r = ws.max_row
    max_c = ws.max_column
    header_font = Font(bold=True)
    for cell in ws[1]:
        cell.font = header_font
        cell.alignment = Alignment(horizontal="center", vertical="center")
    ws.freeze_panes = "A2"
    for col in ws.columns:
        let = col[0].column_letter
        ml = 0
        for c_ in col:
            val = str(c_.value) if c_.value else ""
            ml = max(ml, len(val))
        ws.column_dimensions[let].width = ml + 4
    if max_r > 1:
        ref = f"A1:{get_column_letter(max_c)}{max_r}"
        tbl = Table(displayName=table_name, ref=ref)
        style = TableStyleInfo(name="TableStyleMedium2", showRowStripes=True, showColumnStripes=False, showFirstColumn=False)
        tbl.tableStyleInfo = style
        to_remove = []
        for tname, existing_table in ws.tables.items():
            if tname == table_name:
                to_remove.append(tname)
        for tname in to_remove:
            del ws.tables[tname]
        ws.add_table(tbl)

class EnhancedPDFReport:
    def __init__(self, df_current: pd.DataFrame, df_history: pd.DataFrame, config: Dict):
        self.df_current = df_current
        self.df_history = df_history
        self.config = config
        self.page_count = 0
        self.colors = {"primary": "#800020", "text": "#2C1810", "background": "#FFFFFF"}
        self.logo_path = self.config["paths"].get("LOGO_PATH", "images/company_logo.png")
        self.PAGE_WIDTH = 8.5
        self.PAGE_HEIGHT = 11
    def generate(self) -> Path:
        pdf_path = self._get_pdf_path()
        with PdfPages(pdf_path) as pdf:
            self._cover_page(pdf)
            self._summary_page(pdf)
            self._all_charts(pdf)
        logging.info(f"PDF => {pdf_path}")
        return pdf_path
    def _get_pdf_path(self) -> Path:
        stamp = datetime.now().strftime("%Y-%m-%d")
        out_dir = Path("Reconciliation_pdf")
        out_dir.mkdir(parents=True, exist_ok=True)
        pdf_name = f"Reconciliation_{stamp}.pdf"
        return out_dir / pdf_name
    def _new_page(self) -> plt.Figure:
        self.page_count += 1
        fig = plt.figure(figsize=(self.PAGE_WIDTH, self.PAGE_HEIGHT))
        fig.patch.set_facecolor(self.colors["background"])
        plt.axis("off")
        if self.logo_path and os.path.exists(self.logo_path):
            try:
                import matplotlib.image as mpimg
                img = mpimg.imread(self.logo_path)
                ax_img = fig.add_axes([0.65, 0.75, 0.3, 0.2])
                ax_img.imshow(img, alpha=0.2)
                ax_img.axis("off")
            except Exception as e:
                logging.error(f"Logo => {e}")
        fig.text(0.5, 0.98, "Reconciliation Report", ha="center", fontsize=10, color="gray")
        fig.text(0.9, 0.03, f"Page {self.page_count}", ha="right", fontsize=8, color="gray")
        fig.text(0.5, 0.02, "Â© Ultra-Mega Reconciliation", ha="center", fontsize=8, color="gray")
        return fig
    def _cover_page(self, pdf: PdfPages):
        fig = self._new_page()
        date_today = datetime.now().strftime("%Y-%m-%d")
        plt.text(0.5, 0.7, "Reconciliation Analysis Report", ha="center", fontsize=24, fontweight="bold", color=self.colors["primary"], transform=fig.transFigure)
        plt.text(0.5, 0.6, f"Generated on {date_today}", ha="center", fontsize=12, color=self.colors["text"], transform=fig.transFigure)
        plt.text(0.5, 0.15, "CONFIDENTIAL", ha="center", fontsize=9, color=self.colors["text"], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)
    def _summary_page(self, pdf: PdfPages):
        fig = self._new_page()
        plt.text(0.5, 0.92, "Reconciliation Summary", ha="center", fontsize=18, fontweight="bold", color=self.colors["primary"], transform=fig.transFigure)
        y = 0.75
        if self.df_current.empty:
            plt.text(0.5, y, "No mismatches/case found.", ha="center", fontsize=14, color=self.colors["text"], transform=fig.transFigure)
        else:
            tot = len(self.df_current)
            c_xrp = (self.df_current["Status"] == "Missing in XRP").sum()
            c_mas = (self.df_current["Status"] == "Missing in Master").sum()
            c_both = (self.df_current["Status"] == "Difference in both").sum()
            c_case = (self.df_current["Status"] == "CASE").sum()
            lines = [
                f"Total Issues: {tot}",
                f"Missing in XRP: {c_xrp}",
                f"Missing in Master: {c_mas}",
                f"Difference in both: {c_both}",
                f"CASE only: {c_case}"
            ]
            summary = "\n".join(lines)
            plt.text(0.5, y, summary, ha="center", fontsize=14, color=self.colors["text"], transform=fig.transFigure)
        pdf.savefig(fig)
        plt.close(fig)
    def _chart_page(self, pdf: PdfPages, title: str, plot_func, **kwargs):
        fig = self._new_page()
        fig.suptitle(title, fontsize=14, fontweight="bold", color=self.colors["primary"], y=0.93)
        ax = fig.add_axes([0.30, 0.2, 0.65, 0.55])
        try:
            plot_func(ax, **kwargs)
            pdf.savefig(fig)
        except Exception as e:
            logging.error(f"{title} => {e}")
        plt.close(fig)
    def _all_charts(self, pdf: PdfPages):
        dfc = self.df_current.copy()
        if dfc.empty:
            return
        df_m = dfc[dfc["Status"] != ""]
        if not df_m.empty and {"Dimension", "Attribute"}.issubset(df_m.columns):
            pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
            if not pivot.empty:
                self._chart_page(pdf, "Heatmap", self._plot_heatmap, pivot=pivot)
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if not cdim.empty:
            self._chart_page(pdf, "Lollipop", self._plot_lollipop, cdim=cdim)
        cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr.empty:
            self._chart_page(pdf, "Circular", self._plot_circular, cattr=cattr)
        cdim_sc = df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim_sc.sort_values("Count", ascending=False, inplace=True)
        cdim_sc = cdim_sc.head(10)
        if not cdim_sc.empty:
            self._chart_page(pdf, "Scatter", self._plot_scatter, cdim=cdim_sc)
        cdim_ra = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False).head(10)
        if len(cdim_ra) > 1:
            self._chart_page(pdf, "Radar", self._plot_radar, cdim=cdim_ra)
        dist = df_m["Status"].value_counts()
        if not dist.empty:
            self._chart_page(pdf, "Pie Chart", self._plot_pie, dist=dist)
        cattr_b = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False).head(10)
        if not cattr_b.empty:
            self._chart_page(pdf, "Bar Chart", self._plot_bar, cattr=cattr_b)
        if not self.df_history.empty and "RunDate" in self.df_history.columns:
            date_ct = self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct.sort_values("RunDate", inplace=True)
            if not date_ct.empty:
                self._chart_page(pdf, "Bollinger with Candlesticks", self._plot_bollinger, date_ct=date_ct)
    def _plot_heatmap(self, ax, pivot):
        im = ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45, ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        ax.set_title("Heatmap")
        plt.colorbar(im, ax=ax)
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                i, j = map(int, np.round(sel.index))
                dim_ = pivot.index[i]
                att_ = pivot.columns[j]
                val_ = pivot.iloc[i, j]
                sel.annotation.set_text(f"{dim_}\n{att_}\nCount={val_}")
    def _plot_lollipop(self, ax, cdim):
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_xlabel("Count")
        ax.set_title("Lollipop Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = int(sel.index)
                dim_ = cdim.index[idx]
                val_ = cdim.values[idx]
                sel.annotation.set_text(f"{dim_}\nCount={val_}")
    def _plot_circular(self, ax, cattr):
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=8)
        ax.bar(angles, cattr.values, width=0.4, alpha=0.6)
        ax.set_title("Circular Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                att_ = cattr.index[idx]
                val_ = cattr.values[idx]
                sel.annotation.set_text(f"{att_}\nCount={val_}")
    def _plot_scatter(self, ax, cdim):
        xvals = np.arange(len(cdim))
        yvals = cdim["Count"].values
        labs = cdim["Dimension"].values
        ax.scatter(xvals, yvals, color="green")
        for i, la in enumerate(labs):
            ax.text(xvals[i], yvals[i], la, ha="center", va="bottom", rotation=60, fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Count")
        ax.set_title("Scatter Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                dim_ = labs[idx]
                val_ = yvals[idx]
                sel.annotation.set_text(f"{dim_}\nCount={val_}")
    def _plot_radar(self, ax, cdim):
        cat = cdim.index.tolist()
        val = cdim.values.tolist()
        angles = np.linspace(0, 2*np.pi, len(cat), endpoint=False).tolist()
        angles += angles[:1]
        val += val[:1]
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=8)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index % (len(cat))
                sel.annotation.set_text(f"{cat[idx]}\nCount={val[idx]}")
    def _plot_pie(self, ax, dist):
        ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax.patches, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                st_ = dist.index[idx]
                val_ = dist.values[idx]
                sel.annotation.set_text(f"{st_}\nCount={val_}")
    def _plot_bar(self, ax, cattr):
        bars = ax.bar(range(len(cattr)), cattr.values)
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right", fontsize=8)
        ax.set_ylabel("Count")
        ax.set_title("Bar Chart")
        for b in bars:
            h = b.get_height()
            ax.text(b.get_x() + b.get_width()/2., h, str(int(h)), ha="center", va="bottom")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(bars, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                att_ = cattr.index[idx]
                val_ = cattr.values[idx]
                sel.annotation.set_text(f"{att_}\nCount={val_}")
        plt.tight_layout()
    def _plot_bollinger(self, ax, date_ct):
        date_ct["RunDate_dt"] = pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True, inplace=True)
        date_ct["rolling_mean"] = date_ct["Count"].rolling(3, min_periods=1).mean()
        date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
        date_ct["upper_band"] = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
        date_ct["lower_band"] = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]
        xvals = np.arange(len(date_ct))
        ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"], color="gray", alpha=0.2)
        ax.plot(xvals, date_ct["rolling_mean"], color="orange", label="Rolling Mean", linewidth=2)
        for i in range(len(date_ct)):
            if i == 0:
                o_ = date_ct["rolling_mean"].iloc[i]
            else:
                o_ = date_ct["rolling_mean"].iloc[i-1]
            c_ = date_ct["rolling_mean"].iloc[i]
            h_ = date_ct["upper_band"].iloc[i]
            l_ = date_ct["lower_band"].iloc[i]
            color = "green" if c_ >= o_ else "red"
            ax.plot([i, i], [l_, h_], color="black", linewidth=1)
            body_low = min(o_, c_)
            body_high = max(o_, c_)
            ax.add_patch(Rectangle((i-0.3, body_low), 0.6, body_high - body_low, fill=True, color=color, alpha=0.4))
        sc = ax.scatter(xvals, date_ct["Count"], color="blue", label="Count", zorder=3)
        ax.set_xticks(xvals)
        xlabels = [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels, rotation=45, ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Candlestick")
        ax.legend()
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(sc, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                date_ = date_ct["RunDate"].iloc[idx]
                val_ = date_ct["Count"].iloc[idx]
                mean_ = date_ct["rolling_mean"].iloc[idx]
                up_ = date_ct["upper_band"].iloc[idx]
                low_ = date_ct["lower_band"].iloc[idx]
                sel.annotation.set_text(f"Date={date_}\nCount={val_}\nMean={mean_:.2f}\nUpper={up_:.2f}\nLower={low_:.2f}")
        self.plot_chart(frame, fig)
    def plot_chart(self, frame: ctk.CTkFrame, fig: plt.Figure):
        self.clear_frame(frame)
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        toolbar_frame = ctk.CTkFrame(frame)
        toolbar_frame.pack(side="top", fill="x")
        tb = NavigationToolbar2Tk(canvas, toolbar_frame)
        tb.update()
        canvas.get_tk_widget().pack(fill="both", expand=True)
        plt.close(fig)
    def clear_frame(self, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()

class SimplePreview(ctk.CTkFrame):
    FILTERABLE = {"Start Date", "End Date"}
    def __init__(self, parent, name: str, cfg_sub: Dict, has_enabled_toggle: bool=False):
        super().__init__(parent)
        self.name = name
        self.df = pd.DataFrame()
        self.filters: Dict[str, Set[str]] = {}
        self.future_var = tk.BooleanVar(value=False)
        self.enabled_only_var = tk.BooleanVar(value=False)
        self.has_enabled_toggle = has_enabled_toggle
        if "filters" in cfg_sub:
            for col, arr in cfg_sub["filters"].items():
                if isinstance(arr, list):
                    self.filters[col] = set(arr)
        if "future_end_toggle" in cfg_sub:
            self.future_var.set(bool(cfg_sub["future_end_toggle"]))
        self.build_ui()
    def build_ui(self):
        top = ctk.CTkFrame(self, fg_color="#f0f0f0")
        top.pack(fill="x", padx=5, pady=5)
        ctk.CTkLabel(top, text=f"{self.name} Preview", fg_color="#800020", corner_radius=8, text_color="white", font=ctk.CTkFont(size=14, weight="bold")).pack(side="left", padx=5)
        ctk.CTkCheckBox(top, text="Future End Date?", variable=self.future_var, command=self.refresh_table, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(side="left", padx=5)
        if self.has_enabled_toggle:
            ctk.CTkCheckBox(top, text="Enabled Only?", variable=self.enabled_only_var, command=self.refresh_table, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(side="left", padx=5)
        ctk.CTkButton(top, text="Clear Date Filters", command=self.clear_filters, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        container = ctk.CTkFrame(self)
        container.pack(fill="both", expand=True)
        self.tree = ttk.Treeview(container, show="headings")
        vsb = ttk.Scrollbar(container, orient="vertical", command=self.tree.yview)
        hsb = ttk.Scrollbar(container, orient="horizontal", command=self.tree.xview)
        self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
        self.tree.grid(row=0, column=0, sticky="nsew")
        vsb.grid(row=0, column=1, sticky="ns")
        hsb.grid(row=1, column=0, sticky="ew")
        container.rowconfigure(0, weight=1)
        container.columnconfigure(0, weight=1)
        self.stat_lab = ctk.CTkLabel(self, text="0 rows", fg_color="#f0f0f0", text_color="black")
        self.stat_lab.pack(fill="x")
    def set_data(self, df: pd.DataFrame):
        self.df = df.copy()
        self.refresh_table()
    def get_filters(self) -> Dict[str, Set[str]]:
        return self.filters
    def get_future_toggle(self) -> bool:
        return bool(self.future_var.get())
    def get_filtered_df(self) -> pd.DataFrame:
        return self.apply_filters()
    def refresh_table(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if self.df.empty:
            self.tree["columns"] = []
            self.stat_lab.configure(text="0 rows")
            return
        cols = list(self.df.columns)
        self.tree["columns"] = cols
        for c in cols:
            self.tree.heading(c, text=c, anchor="w", command=lambda cc=c: self.on_col_click(cc))
            self.tree.column(c, anchor="w", width=150)
        df_f = self.apply_filters()
        for _, row in df_f.iterrows():
            rowvals = [row.get(col, "") for col in cols]
            self.tree.insert("", "end", values=rowvals)
        self.stat_lab.configure(text=f"{len(df_f)} rows")
    def apply_filters(self) -> pd.DataFrame:
        df_f = self.df.copy()
        for col, allowed in self.filters.items():
            if col not in df_f.columns:
                continue
            if not allowed:
                df_f = df_f.iloc[0:0]
                return df_f
            def keeper(x):
                if pd.isna(x):
                    return ("<<NaN>>" in allowed)
                elif isinstance(x, str) and not x.strip():
                    return ("<<BLANK>>" in allowed)
                else:
                    return str(x) in allowed
            df_f = df_f[df_f[col].apply(keeper)]
        if self.future_var.get() and "End Date" in df_f.columns:
            today_ = date.today()
            keep_set = set()
            for v in df_f["End Date"].unique():
                if pd.isna(v) or (isinstance(v, str) and not v.strip()):
                    keep_set.add(v)
                    continue
                sval = str(v).strip()
                keep = False
                try:
                    dtp = datetime.strptime(sval, "%Y-%m-%d")
                    if dtp.date() >= today_ or dtp.year > 2200:
                        keep = True
                except:
                    if "9999" in sval:
                        keep = True
                    else:
                        import re
                        yrs = re.findall(r"\d{4}", sval)
                        for y_ in yrs:
                            try:
                                if int(y_) > 2200:
                                    keep = True
                                    break
                            except:
                                pass
                if keep:
                    keep_set.add(v)
            df_f = df_f[df_f["End Date"].isin(keep_set)]
        if self.has_enabled_toggle and self.enabled_only_var.get():
            if "Enabled_F" in df_f.columns:
                df_f = df_f[df_f["Enabled_F"] == "Enabled"]
        return df_f
    def on_col_click(self, col_name: str):
        if col_name in self.FILTERABLE:
            self.show_filter_popup(col_name)
    def show_filter_popup(self, col_name: str):
        if self.df.empty or col_name not in self.df.columns:
            return
        pop = tk.Toplevel(self)
        pop.title(f"Filter: {col_name}")
        pop.geometry("300x400")
        fr = ctk.CTkFrame(pop)
        fr.pack(fill="both", expand=True, padx=5, pady=5)
        unq = self.df[col_name].unique()
        dsp_map = {}
        rev_map = {}
        for v in unq:
            if pd.isna(v):
                dsp = "(NaN)"
                sen = "<<NaN>>"
            elif isinstance(v, str) and not v.strip():
                dsp = "(blank)"
                sen = "<<BLANK>>"
            else:
                dsp = str(v)
                sen = dsp
            dsp_map[v] = dsp
            rev_map[dsp] = sen
        sortd = sorted(dsp_map.values(), key=lambda x: x.lower())
        curr = self.filters.get(col_name, set())
        all_sens = set(rev_map.values())
        selall_var = tk.BooleanVar(value=(curr == all_sens or not curr))
        def toggle_all():
            c = selall_var.get()
            for vb in var_dict.values():
                vb.set(c)
        ctk.CTkCheckBox(fr, text="Select All", variable=selall_var, command=toggle_all, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(anchor="w", pady=5)
        scr = ctk.CTkScrollableFrame(fr, width=250, height=250)
        scr.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict = {}
        for dsp in sortd:
            sen = rev_map[dsp]
            in_f = (sen in curr) or (not curr)
            bvar = tk.BooleanVar(value=in_f)
            var_dict[dsp] = bvar
            ctk.CTkCheckBox(scr, text=dsp, variable=bvar, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(anchor="w")
        def apply_():
            sel = {rev_map[d] for d, bv in var_dict.items() if bv.get()}
            if sel == all_sens or not sel:
                if col_name in self.filters:
                    del self.filters[col_name]
            else:
                self.filters[col_name] = sel
            pop.destroy()
            self.refresh_table()
        bf = ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=pop.destroy, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
    def clear_filters(self):
        to_del = []
        for c in self.filters:
            if c in self.FILTERABLE:
                to_del.append(c)
        for d in to_del:
            del self.filters[d]
        self.future_var.set(False)
        self.refresh_table()

class AdvancedDashboard(ctk.CTkFrame):
    def __init__(self, parent, config: Dict):
        super().__init__(parent)
        dash_cfg = config.get("dashboard", {})
        self.config = config
        self.selected_dims = set(dash_cfg.get("selected_dims", []))
        self.selected_attrs = set(dash_cfg.get("selected_attrs", []))
        self.top_n = dash_cfg.get("top_n", 10)
        self.df_current = pd.DataFrame()
        self.df_history = pd.DataFrame()
        topbar = ctk.CTkScrollableFrame(self, orientation="horizontal", height=60)
        topbar.pack(fill="x", pady=5)
        self.metric_label = ctk.CTkLabel(topbar, text="Metrics: 0 mismatch, 0 dimension", width=300)
        self.metric_label.pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Dimension", command=self.show_dim_filter, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Filter Attribute", command=self.show_attr_filter, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(topbar, text="Toggle Top 10 / All", command=self.toggle_top_n, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        self.notebook = ttk.Notebook(self)
        self.notebook.pack(fill="both", expand=True)
        chart_names = ["Heatmap", "Lollipop", "Circular", "Scatter", "Radar", "Normal Pie", "Normal Bar", "Bollinger Chart"]
        self.frames = {}
        for nm in chart_names:
            fr = ctk.CTkFrame(self.notebook)
            fr.pack(fill="both", expand=True)
            self.notebook.add(fr, text=nm)
            self.frames[nm] = fr
    def toggle_top_n(self):
        if self.top_n == 10:
            self.top_n = None
        else:
            self.top_n = 10
        self.update_data_filters()
    def show_dim_filter(self):
        self.show_filter_popup("Dimension")
    def show_attr_filter(self):
        self.show_filter_popup("Attribute")
    def show_filter_popup(self, col: str):
        base = self.df_history if not self.df_history.empty else self.df_current
        if base.empty or col not in base.columns:
            return
        pop = tk.Toplevel(self)
        pop.title(f"Filter: {col}")
        pop.geometry("300x400")
        fr = ctk.CTkFrame(pop)
        fr.pack(fill="both", expand=True, padx=5, pady=5)
        unq = base[col].dropna().unique()
        dsp_map = {}
        for v in unq:
            dsp = str(v) if isinstance(v, str) and v.strip() else "(blank)"
            dsp_map[v] = dsp
        svals = sorted(dsp_map.keys(), key=lambda x: dsp_map[x].lower())
        if col == "Dimension":
            curr = self.selected_dims
        else:
            curr = self.selected_attrs
        if not curr:
            curr = set(svals)
        all_vals = set(svals)
        selall_var = tk.BooleanVar(value=(curr == all_vals or not curr))
        def toggle_all():
            c = selall_var.get()
            for vb in var_dict.values():
                vb.set(c)
        ctk.CTkCheckBox(fr, text="Select All", variable=selall_var, command=toggle_all, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(anchor="w", pady=5)
        scr = ctk.CTkScrollableFrame(fr, width=250, height=250)
        scr.pack(fill="both", expand=True, padx=5, pady=5)
        var_dict = {}
        for rv in svals:
            in_f = (rv in curr) or (not curr)
            bvar = tk.BooleanVar(value=in_f)
            var_dict[rv] = bvar
            ctk.CTkCheckBox(scr, text=dsp_map[rv], variable=bvar, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(anchor="w")
        def apply_():
            sel = {k for k, bv in var_dict.items() if bv.get()}
            if col == "Dimension":
                self.selected_dims = sel
            else:
                self.selected_attrs = sel
            pop.destroy()
            self.update_data_filters()
        bf = ctk.CTkFrame(fr)
        bf.pack(fill="x", pady=5)
        ctk.CTkButton(bf, text="Apply", command=apply_, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Cancel", command=pop.destroy, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
    def update_data(self, df_current: pd.DataFrame, df_history: pd.DataFrame):
        self.df_current = df_current.copy()
        self.df_history = df_history.copy()
        self.update_data_filters()
    def update_data_filters(self):
        dfc = self.df_current.copy()
        if not dfc.empty:
            if self.selected_dims:
                dfc = dfc[dfc["Dimension"].isin(self.selected_dims)]
            if self.selected_attrs:
                dfc = dfc[dfc["Attribute"].isin(self.selected_attrs)]
        mism = len(dfc)
        dims = dfc["Dimension"].nunique() if not dfc.empty and "Dimension" in dfc.columns else 0
        self.metric_label.configure(text=f"Mismatches: {mism}, Dims: {dims}")
        self.build_heatmap(dfc, self.frames["Heatmap"])
        self.build_lollipop(dfc, self.frames["Lollipop"])
        self.build_circular(dfc, self.frames["Circular"])
        self.build_scatter(dfc, self.frames["Scatter"])
        self.build_radar(dfc, self.frames["Radar"])
        self.build_pie(dfc, self.frames["Normal Pie"])
        self.build_bar(dfc, self.frames["Normal Bar"])
        self.build_bollinger(self.frames["Bollinger Chart"])
    def clear_frame(self, frame: ctk.CTkFrame):
        for w in frame.winfo_children():
            w.destroy()
    def plot_chart(self, frame: ctk.CTkFrame, fig: plt.Figure):
        self.clear_frame(frame)
        canvas = FigureCanvasTkAgg(fig, master=frame)
        canvas.draw()
        toolbar_frame = ctk.CTkFrame(frame)
        toolbar_frame.pack(side="top", fill="x")
        tb = NavigationToolbar2Tk(canvas, toolbar_frame)
        tb.update()
        canvas.get_tk_widget().pack(fill="both", expand=True)
        plt.close(fig)
    def build_heatmap(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty or "Status" not in df.columns:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty or not {"Dimension", "Attribute"}.issubset(df_m.columns):
            return
        pivot = df_m.groupby(["Dimension", "Attribute"]).size().unstack(fill_value=0)
        if pivot.empty:
            return
        fig, ax = plt.subplots(figsize=(5, 4))
        im = ax.imshow(pivot, aspect="auto", cmap="Reds")
        ax.set_xticks(range(len(pivot.columns)))
        ax.set_xticklabels(pivot.columns, rotation=45, ha="right")
        ax.set_yticks(range(len(pivot.index)))
        ax.set_yticklabels(pivot.index)
        ax.set_title("Heatmap")
        plt.colorbar(im, ax=ax)
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                i, j = map(int, np.round(sel.index))
                dim_ = pivot.index[i]
                att_ = pivot.columns[j]
                val_ = pivot.iloc[i, j]
                sel.annotation.set_text(f"{dim_}\n{att_}\nCount={val_}")
        self.plot_chart(frame, fig)
    def build_lollipop(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty:
            return
        fig, ax = plt.subplots(figsize=(5, 4))
        ax.hlines(y=cdim.index, xmin=0, xmax=cdim.values, color="skyblue")
        ax.plot(cdim.values, cdim.index, "o", color="skyblue")
        ax.set_title("Lollipop")
        ax.set_xlabel("Count")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = int(sel.index)
                dim_ = cdim.index[idx]
                val_ = cdim.values[idx]
                sel.annotation.set_text(f"{dim_}\nCount={val_}")
        self.plot_chart(frame, fig)
    def build_circular(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cattr = df_m.groupby("Attribute")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cattr = cattr.head(10)
        if cattr.empty:
            return
        fig = plt.figure(figsize=(5, 5))
        ax = fig.add_subplot(111, polar=True)
        angles = np.linspace(0, 2*np.pi, len(cattr), endpoint=False)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles)
        ax.set_xticklabels(cattr.index, fontsize=8)
        ax.bar(angles, cattr.values, width=0.4, alpha=0.6)
        ax.set_title("Circular Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                att_ = cattr.index[idx]
                val_ = cattr.values[idx]
                sel.annotation.set_text(f"{att_}\nCount={val_}")
        self.plot_chart(frame, fig)
    def build_scatter(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().reset_index(name="Count")
        cdim.sort_values("Count", ascending=False, inplace=True)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty:
            return
        fig, ax = plt.subplots(figsize=(5, 4))
        xvals = np.arange(len(cdim))
        yvals = cdim["Count"].values
        labs = cdim["Dimension"].values
        ax.scatter(xvals, yvals, color="green")
        for i, la in enumerate(labs):
            ax.text(xvals[i], yvals[i], la, ha="center", va="bottom", rotation=60, fontsize=8)
        ax.set_xticks([])
        ax.set_ylabel("Count")
        ax.set_title("Scatter Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                dim_ = labs[idx]
                val_ = yvals[idx]
                sel.annotation.set_text(f"{dim_}\nCount={val_}")
        self.plot_chart(frame, fig)
    def build_radar(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cdim = df_m.groupby("Dimension")["Key"].count().sort_values(ascending=False)
        if self.top_n == 10:
            cdim = cdim.head(10)
        if cdim.empty or len(cdim) < 2:
            return
        cat = cdim.index.tolist()
        val = cdim.values.tolist()
        angles = np.linspace(0, 2*np.pi, len(cat), endpoint=False).tolist()
        angles += angles[:1]
        val += val[:1]
        fig = plt.figure(figsize=(5, 5))
        ax = fig.add_subplot(111, polar=True)
        ax.set_theta_offset(np.pi/2)
        ax.set_theta_direction(-1)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(cat, fontsize=8)
        ax.plot(angles, val, color="red", linewidth=2)
        ax.fill(angles, val, color="red", alpha=0.3)
        ax.set_title("Radar Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(ax, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index % (len(cat))
                sel.annotation.set_text(f"{cat[idx]}\nCount={val[idx]}")
        self.plot_chart(frame, fig)
    def build_pie(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        dist = df_m["Status"].value_counts()
        if dist.empty:
            return
        fig, ax = plt.subplots(figsize=(5, 4))
        wedges, texts, autotexts = ax.pie(dist.values, labels=dist.index, autopct="%.1f%%", startangle=140)
        ax.set_title("Pie Chart")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(wedges, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                st_ = dist.index[idx]
                val_ = dist.values[idx]
                sel.annotation.set_text(f"{st_}\nCount={val_}")
        self.plot_chart(frame, fig)
    def build_bar(self, df: pd.DataFrame, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if df.empty:
            return
        df_m = df[df["Status"] != ""]
        if df_m.empty:
            return
        cattr = df_m["Attribute"].value_counts().sort_values(ascending=False)
        if self.top_n == 10:
            cattr = cattr.head(10)
        if cattr.empty:
            return
        fig, ax = plt.subplots(figsize=(5, 3))
        bars = ax.bar(range(len(cattr)), cattr.values)
        ax.set_xticks(range(len(cattr)))
        ax.set_xticklabels(cattr.index, rotation=45, ha="right", fontsize=8)
        ax.set_ylabel("Count")
        ax.set_title("Bar Chart")
        for b in bars:
            h = b.get_height()
            ax.text(b.get_x() + b.get_width()/2., h, str(int(h)), ha="center", va="bottom")
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(bars, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                att_ = cattr.index[idx]
                val_ = cattr.values[idx]
                sel.annotation.set_text(f"{att_}\nCount={val_}")
        plt.tight_layout()
        self.plot_chart(frame, fig)
    def build_bollinger(self, frame: ctk.CTkFrame):
        self.clear_frame(frame)
        if self.df_history.empty or "RunDate" not in self.df_history.columns:
            return
        date_ct = self.df_history.groupby("RunDate")["Key"].count().reset_index(name="Count")
        date_ct.sort_values("RunDate", inplace=True)
        if date_ct.empty:
            return
        fig, ax = plt.subplots(figsize=(6, 3))
        date_ct["RunDate_dt"] = pd.to_datetime(date_ct["RunDate"], errors="coerce")
        date_ct.sort_values("RunDate_dt", inplace=True)
        date_ct.reset_index(drop=True, inplace=True)
        date_ct["rolling_mean"] = date_ct["Count"].rolling(3, min_periods=1).mean()
        date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
        date_ct["upper_band"] = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
        date_ct["lower_band"] = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]
        xvals = np.arange(len(date_ct))
        ax.fill_between(xvals, date_ct["lower_band"], date_ct["upper_band"], color="gray", alpha=0.2)
        ax.plot(xvals, date_ct["rolling_mean"], color="orange", label="Rolling Mean", linewidth=2)
        for i in range(len(date_ct)):
            if i == 0:
                o_ = date_ct["rolling_mean"].iloc[i]
            else:
                o_ = date_ct["rolling_mean"].iloc[i-1]
            c_ = date_ct["rolling_mean"].iloc[i]
            h_ = date_ct["upper_band"].iloc[i]
            l_ = date_ct["lower_band"].iloc[i]
            color = "green" if c_ >= o_ else "red"
            ax.plot([i, i], [l_, h_], color="black", linewidth=1)
            body_low = min(o_, c_)
            body_high = max(o_, c_)
            ax.add_patch(Rectangle((i-0.3, body_low), 0.6, body_high-body_low, fill=True, color=color, alpha=0.4))
        sc = ax.scatter(xvals, date_ct["Count"], color="blue", label="Count", zorder=3)
        ax.set_xticks(xvals)
        xlabels = [d.strftime("%Y-%m-%d") if not pd.isna(d) else "" for d in date_ct["RunDate_dt"]]
        ax.set_xticklabels(xlabels, rotation=45, ha="right")
        ax.set_xlabel("RunDate")
        ax.set_ylabel("Mismatch Count")
        ax.set_title("Bollinger Candlestick")
        ax.legend()
        if HAS_MPLCURSORS:
            crs = mplcursors.cursor(sc, hover=True)
            @crs.connect("add")
            def _(sel):
                idx = sel.index
                date_ = date_ct["RunDate"].iloc[idx]
                val_ = date_ct["Count"].iloc[idx]
                mean_ = date_ct["rolling_mean"].iloc[idx]
                up_ = date_ct["upper_band"].iloc[idx]
                low_ = date_ct["lower_band"].iloc[idx]
                sel.annotation.set_text(f"Date={date_}\nCount={val_}\nMean={mean_:.2f}\nUpper={up_:.2f}\nLower={low_:.2f}")
        self.plot_chart(frame, fig)

class HistoryTab(ctk.CTkFrame):
    def __init__(self, parent, hist_dir: Path):
        super().__init__(parent)
        self.history_dir = hist_dir
        self.tree = None
        self.build_ui()
    def build_ui(self):
        lbl = ctk.CTkLabel(self, text="Reconciliation Runs History", font=("Arial", 16))
        lbl.pack(pady=5)
        self.tree = ttk.Treeview(self, columns=("Filename",), show="headings", height=15)
        self.tree.heading("Filename", text="History File")
        self.tree.pack(fill="both", expand=True, padx=10, pady=10)
        self.tree.bind("<Double-1>", self.on_double_click)
        ctk.CTkButton(self, text="Refresh", command=self.refresh_history, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)
        self.refresh_history()
    def refresh_history(self):
        for i in self.tree.get_children():
            self.tree.delete(i)
        if not self.history_dir.is_dir():
            self.history_dir.mkdir(parents=True, exist_ok=True)
        files = sorted(self.history_dir.glob("run_*.json"), reverse=True)
        for f in files:
            self.tree.insert("", "end", values=(f.name,))
    def on_double_click(self, event):
        it = self.tree.focus()
        if not it:
            return
        fn = self.tree.item(it, "values")[0]
        path = self.history_dir / fn
        if not path.is_file():
            return
        try:
            with open(path, "r", encoding="utf-8") as ff:
                content = ff.read()
            pop = tk.Toplevel(self)
            pop.title(f"Viewing {fn}")
            txt = ctk.CTkTextbox(pop, width=800, height=600)
            txt.pack(fill="both", expand=True)
            txt.insert("end", content)
            txt.configure(state="disabled")
        except Exception as e:
            logging.error(f"Error opening {path} => {e}")

class MainApp(ctk.CTk):
    def __init__(self):
        super().__init__()
        self.title("Ultra-Mega => 2-sheet Excel, SHIFTED PDF, Name-Filling, Date Column (YYYY-MM-DD)")
        self.geometry("1600x900")
        ctk.set_appearance_mode("light")
        self.protocol("WM_DELETE_WINDOW", self.on_close)
        self.config_dict = load_config(Path(DEFAULT_PATHS["CONFIG_PATH"]))
        self.param_dict = read_param_file(Path(self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"])))
        self.history_df = pd.DataFrame()
        self.case_history_df = pd.DataFrame()
        self.tabs = ttk.Notebook(self)
        self.tabs.pack(fill="both", expand=True)
        self.tab_paths = ctk.CTkFrame(self.tabs)
        self.build_paths_tab(self.tab_paths)
        self.tabs.add(self.tab_paths, text="Paths")
        e_cfg = self.config_dict.get("xrp_grid", {})
        self.tab_xrp = ctk.CTkFrame(self.tabs)
        self.xrp_preview = SimplePreview(self.tab_xrp, "XRP", e_cfg, has_enabled_toggle=True)
        self.xrp_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_xrp, text="XRP Preview")
        m_cfg = self.config_dict.get("master_grid", {})
        self.tab_master = ctk.CTkFrame(self.tabs)
        self.master_preview = SimplePreview(self.tab_master, "Master", m_cfg, has_enabled_toggle=False)
        self.master_preview.pack(fill="both", expand=True)
        self.tabs.add(self.tab_master, text="Master Preview")
        self.tab_compare = ctk.CTkFrame(self.tabs)
        self.build_compare_tab(self.tab_compare)
        self.tabs.add(self.tab_compare, text="Compare")
        self.dashboard_tab = AdvancedDashboard(self.tabs, self.config_dict)
        self.tabs.add(self.dashboard_tab, text="Dashboard")
        histp = Path(self.config_dict["paths"].get("HISTORY_PATH", "history_runs"))
        self.history_tab = HistoryTab(self.tabs, histp)
        self.tabs.add(self.history_tab, text="History")
        self.log_box = ctk.CTkTextbox(self, height=120)
        self.log_box.pack(fill="both", side="bottom")
        self.log_box.configure(state="disabled")
        handler = TextHandler(self.log_box)
        handler.setLevel(logging.INFO)
        logging.getLogger().addHandler(handler)
        self.temp_csv_dir = Path(self.config_dict["paths"].get("MASTER_CSV_OUTPUT", "temp_master_csv"))
        self.temp_csv_dir.mkdir(parents=True, exist_ok=True)
        self.load_history_runs()
        self.load_case_history_runs()
        self.refresh_xrp()
        self.refresh_master()
        self.dashboard_tab.update_data(pd.DataFrame(), self.history_df)
        ctk.CTkButton(self, text="Close", command=self.on_close, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=5)
    def build_paths_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        self.xrp_var = tk.StringVar(value=self.config_dict["paths"].get("xrp_EXCEL_PATH", DEFAULT_PATHS["xrp_EXCEL_PATH"]))
        self.mast_zip_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_ZIP_PATH", DEFAULT_PATHS["MASTER_ZIP_PATH"]))
        self.mast_folder_var = tk.StringVar(value=self.config_dict["paths"].get("MASTER_TXT_FOLDER", ""))
        self.exc_var = tk.StringVar(value=self.config_dict["paths"].get("EXCEPTION_PATH", DEFAULT_PATHS["EXCEPTION_PATH"]))
        self.out_var = tk.StringVar(value=self.config_dict["paths"].get("OUTPUT_PATH", DEFAULT_PATHS["OUTPUT_PATH"]))
        self.par_var = tk.StringVar(value=self.config_dict["paths"].get("PARAMETER_PATH", DEFAULT_PATHS["PARAMETER_PATH"]))
        self.pdf_var = tk.StringVar(value=self.config_dict["paths"].get("PDF_EXPORT_PATH", DEFAULT_PATHS["PDF_EXPORT_PATH"]))
        def mkrow(lbl, var, is_dir=False):
            rowf = ctk.CTkFrame(frm)
            rowf.pack(fill="x", pady=5)
            ctk.CTkLabel(rowf, text=lbl, width=200).pack(side="left", padx=5)
            e = ctk.CTkEntry(rowf, textvariable=var, width=600)
            e.pack(side="left", padx=5)
            def br():
                if is_dir:
                    p = filedialog.askdirectory()
                else:
                    p = filedialog.askopenfilename()
                if p:
                    var.set(p)
            ctk.CTkButton(rowf, text="Browse", command=br, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        mkrow("XRP Excel:", self.xrp_var)
        mkrow("Master ZIP:", self.mast_zip_var)
        mkrow("Master Folder:", self.mast_folder_var, True)
        mkrow("Exception Path:", self.exc_var)
        mkrow("Missing Items Output:", self.out_var)
        mkrow("Parameter File:", self.par_var)
        mkrow("PDF Export Path:", self.pdf_var)
        bf = ctk.CTkFrame(frm)
        bf.pack(fill="x", pady=10)
        ctk.CTkButton(bf, text="Save Config", command=self.save_all_config, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh XRP", command=self.refresh_xrp, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
        ctk.CTkButton(bf, text="Refresh Master", command=self.refresh_master, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(side="left", padx=5)
    def build_compare_tab(self, parent):
        frm = ctk.CTkFrame(parent)
        frm.pack(fill="both", expand=True, padx=10, pady=10)
        ctk.CTkLabel(frm, text="Generate 2-Sheet Excel => Mismatch + Case_Differences, with Name-Filling & Date (YYYY-MM-DD), SHIFTED PDF, and Dashboard", font=ctk.CTkFont(size=14, weight="bold")).pack(pady=5)
        self.trim_key_var = tk.BooleanVar(value=self.config_dict.get("trim_key_toggle", False))
        ctk.CTkCheckBox(frm, text="Trim Key?", variable=self.trim_key_var, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(pady=5)
        self.include_case_var = tk.BooleanVar(value=self.config_dict.get("include_case_in_report", False))
        ctk.CTkCheckBox(frm, text="Include CASE in Dashboard/PDF?", variable=self.include_case_var, fg_color="#800020", hover_color="#a52a2a", text_color="black").pack(pady=5)
        ctk.CTkButton(frm, text="Run Reconciliation", command=self.run_comparison, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=10)
        ctk.CTkButton(frm, text="Export PDF Report", command=self.export_pdf, fg_color="#800020", hover_color="#a52a2a", text_color="white").pack(pady=10)
    def load_history_runs(self):
        histp = Path(self.config_dict["paths"].get("HISTORY_PATH", "history_runs"))
        if not histp.is_dir():
            return
        frames = []
        for jf in histp.glob("run_*.json"):
            try:
                df_ = pd.read_json(jf, orient="records")
                frames.append(df_)
            except Exception as e:
                logging.error(f"History => {jf} => {e}")
        if frames:
            big = pd.concat(frames, ignore_index=True).drop_duplicates()
            if self.history_df.empty:
                self.history_df = big
            else:
                self.history_df = pd.concat([self.history_df, big], ignore_index=True).drop_duplicates()
            logging.info(f"Loaded mismatch => total {len(self.history_df)} records")
    def load_case_history_runs(self):
        casep = Path(self.config_dict["paths"].get("CASE_HISTORY_PATH", "case_history_runs"))
        if not casep.is_dir():
            return
        frames = []
        for jf in casep.glob("case_run_*.json"):
            try:
                df_ = pd.read_json(jf, orient="records")
                frames.append(df_)
            except Exception as e:
                logging.error(f"CASE => {jf} => {e}")
        if frames:
            big = pd.concat(frames, ignore_index=True).drop_duplicates()
            if self.case_history_df.empty:
                self.case_history_df = big
            else:
                self.case_history_df = pd.concat([self.case_history_df, big], ignore_index=True).drop_duplicates()
            logging.info(f"Loaded case => total {len(self.case_history_df)} records")
    def refresh_xrp(self):
        path_ = Path(self.config_dict["paths"].get("xrp_EXCEL_PATH", "data/xrp_Config.xlsx")).resolve()
        df = read_xrp_excel(path_)
        if df.empty:
            self.xrp_preview.set_data(pd.DataFrame())
            return
        meltdown_ = meltdown_xrp_for_preview(df, self.param_dict)
        pivot_ = pivot_for_preview(meltdown_)
        self.xrp_preview.set_data(pivot_)
    def refresh_master(self):
        folder_ = self.config_dict["paths"].get("MASTER_TXT_FOLDER", "")
        zpath_ = self.config_dict["paths"].get("MASTER_ZIP_PATH", "")
        folder_p = Path(folder_).resolve() if folder_ else None
        if folder_p and folder_p.is_dir():
            dfm = unify_master_txt_in_folder(folder_p)
        else:
            z_p = Path(zpath_)
            cfiles = convert_master_txt_to_csv(z_p, self.temp_csv_dir)
            dfm = unify_master_csvs(cfiles)
        if dfm.empty:
            self.master_preview.set_data(pd.DataFrame())
            return
        meltdown_ = meltdown_master_for_preview(dfm, self.param_dict)
        pivot_ = pivot_for_preview(meltdown_)
        self.master_preview.set_data(pivot_)
    def run_comparison(self):
        df_xrp_w = self.xrp_preview.get_filtered_df()
        df_mast_w = self.master_preview.get_filtered_df()
        xrp_long = meltdown_to_long(df_xrp_w)
        mast_long = meltdown_to_long(df_mast_w)
        diagnose_type_mismatches(xrp_long, mast_long)
        trim_flag = bool(self.trim_key_var.get())
        mismatch_df, case_df = compare_name_first(xrp_long, mast_long, trim_key=trim_flag)
        exc_path = Path(self.config_dict["paths"].get("EXCEPTION_PATH", ""))
        df_exc = read_exception_table(exc_path)
        mismatch_df = merge_exceptions(mismatch_df, df_exc)
        case_df = merge_exceptions(case_df, df_exc)
        date_today_str = datetime.now().strftime("%Y-%m-%d")
        mismatch_df["Date"] = date_today_str
        case_df["Date"] = date_today_str
        outp = Path(self.config_dict["paths"].get("OUTPUT_PATH", "output/missing_items.xlsx"))
        write_missing_items_excel(mismatch_df, case_df, outp)
        run_ts = datetime.now().strftime("%Y-%m-%d")
        mismatch_df["RunDate"] = run_ts
        case_df["RunDate"] = run_ts
        if self.history_df.empty:
            self.history_df = mismatch_df.copy()
        else:
            self.history_df = pd.concat([self.history_df, mismatch_df], ignore_index=True).drop_duplicates()
        if self.case_history_df.empty:
            self.case_history_df = case_df.copy()
        else:
            self.case_history_df = pd.concat([self.case_history_df, case_df], ignore_index=True).drop_duplicates()
        histp = Path(self.config_dict["paths"].get("HISTORY_PATH", "history_runs"))
        histp.mkdir(parents=True, exist_ok=True)
        run_file = histp / f"run_{run_ts.replace('-', '_')}.json"
        try:
            mismatch_df.to_json(run_file, orient="records", indent=2)
            logging.info(f"Saved mismatch => {run_file}")
        except Exception as e:
            logging.error(f"Error => {e}")
        casep = Path(self.config_dict["paths"].get("CASE_HISTORY_PATH", "case_history_runs"))
        casep.mkdir(parents=True, exist_ok=True)
        case_file = casep / f"case_run_{run_ts.replace('-', '_')}.json"
        try:
            case_df.to_json(case_file, orient="records", indent=2)
            logging.info(f"Saved case => {case_file}")
        except Exception as e:
            logging.error(f"Case => {e}")
        self._save_bollinger_data(self.history_df, "BOLLINGER_JSON_PATH")
        self._save_bollinger_data(self.case_history_df, "CASE_BOLLINGER_JSON_PATH")
        if self.include_case_var.get():
            combined_df = pd.concat([mismatch_df, case_df], ignore_index=True)
            combined_hist = pd.concat([self.history_df, self.case_history_df], ignore_index=True).drop_duplicates()
        else:
            combined_df = mismatch_df.copy()
            combined_hist = self.history_df
        self.dashboard_tab.update_data(combined_df, combined_hist)
        self.history_tab.refresh_history()
        self.tabs.select(self.dashboard_tab)
        messagebox.showinfo("Done", f"Missing items => {outp}")
    def _save_bollinger_data(self, df: pd.DataFrame, path_key: str):
        if df.empty or "RunDate" not in df.columns:
            return
        try:
            path_str = self.config_dict["paths"].get(path_key, "")
            if not path_str:
                return
            outp = Path(path_str)
            outp.parent.mkdir(parents=True, exist_ok=True)
            date_ct = df.groupby("RunDate")["Key"].count().reset_index(name="Count")
            date_ct["RunDate_dt"] = pd.to_datetime(date_ct["RunDate"], errors="coerce", format="%Y-%m-%d")
            date_ct.sort_values("RunDate_dt", inplace=True)
            date_ct.reset_index(drop=True, inplace=True)
            date_ct["rolling_mean"] = date_ct["Count"].rolling(3, min_periods=1).mean()
            date_ct["rolling_std"] = date_ct["Count"].rolling(3, min_periods=1).std(ddof=0)
            date_ct["upper_band"] = date_ct["rolling_mean"] + 2*date_ct["rolling_std"]
            date_ct["lower_band"] = date_ct["rolling_mean"] - 2*date_ct["rolling_std"]
            date_ct["RunDate"] = date_ct["RunDate_dt"].dt.strftime("%Y-%m-%d")
            date_ct.drop(columns=["RunDate_dt"], inplace=True)
            date_ct.to_json(outp, orient="records", indent=2)
            logging.info(f"Bollinger => {outp}")
        except Exception as e:
            logging.error(f"Bollinger => {e}")
    def export_pdf(self):
        if self.history_df.empty and self.case_history_df.empty:
            messagebox.showinfo("PDF Export", "No data => empty history.")
            return
        last_run = None
        if not self.history_df.empty and "RunDate" in self.history_df.columns:
            last_run = self.history_df["RunDate"].max()
        if last_run:
            df_curr = self.history_df[self.history_df["RunDate"] == last_run].copy()
        else:
            df_curr = self.history_df.copy()
        if self.include_case_var.get() and not self.case_history_df.empty:
            case_last = self.case_history_df["RunDate"].max()
            if case_last == last_run:
                case_curr = self.case_history_df[self.case_history_df["RunDate"] == case_last].copy()
                df_curr = pd.concat([df_curr, case_curr], ignore_index=True)
        if self.include_case_var.get():
            big_hist = pd.concat([self.history_df, self.case_history_df], ignore_index=True).drop_duplicates()
        else:
            big_hist = self.history_df
        rep = EnhancedPDFReport(df_curr, big_hist, self.config_dict)
        pdfp = rep.generate()
        messagebox.showinfo("PDF Export", f"PDF => {pdfp}")
    def save_all_config(self):
        self.config_dict["paths"]["xrp_EXCEL_PATH"] = self.xrp_var.get().strip()
        self.config_dict["paths"]["MASTER_ZIP_PATH"] = self.mast_zip_var.get().strip()
        self.config_dict["paths"]["MASTER_TXT_FOLDER"] = self.mast_folder_var.get().strip()
        self.config_dict["paths"]["EXCEPTION_PATH"] = self.exc_var.get().strip()
        self.config_dict["paths"]["OUTPUT_PATH"] = self.out_var.get().strip()
        self.config_dict["paths"]["PARAMETER_PATH"] = self.par_var.get().strip()
        self.config_dict["paths"]["PDF_EXPORT_PATH"] = self.pdf_var.get().strip()
        self.config_dict["trim_key_toggle"] = bool(self.trim_key_var.get())
        self.config_dict["include_case_in_report"] = bool(self.include_case_var.get())
        e_cfg = self.config_dict.setdefault("xrp_grid", {})
        e_cfg["filters"] = self.xrp_preview.get_filters()
        e_cfg["future_end_toggle"] = self.xrp_preview.get_future_toggle()
        m_cfg = self.config_dict.setdefault("master_grid", {})
        m_cfg["filters"] = self.master_preview.get_filters()
        m_cfg["future_end_toggle"] = self.master_preview.get_future_toggle()
        dash_cfg = self.config_dict.setdefault("dashboard", {})
        dash_cfg["selected_dims"] = list(self.dashboard_tab.selected_dims)
        dash_cfg["selected_attrs"] = list(self.dashboard_tab.selected_attrs)
        dash_cfg["top_n"] = self.dashboard_tab.top_n
        cfgp = Path(self.config_dict["paths"].get("CONFIG_PATH", "config/ui_config.json"))
        save_config(self.config_dict, cfgp)
    def on_close(self):
        self.save_all_config()
        self._save_bollinger_data(self.history_df, "BOLLINGER_JSON_PATH")
        self._save_bollinger_data(self.case_history_df, "CASE_BOLLINGER_JSON_PATH")
        self.destroy()

def main():
    app = MainApp()
    app.mainloop()

if __name__ == "__main__":
    main()
